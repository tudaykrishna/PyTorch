{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    "    target_transform=None\n",
    "    )\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0,\n",
       " 'aquarium_fish': 1,\n",
       " 'baby': 2,\n",
       " 'bear': 3,\n",
       " 'beaver': 4,\n",
       " 'bed': 5,\n",
       " 'bee': 6,\n",
       " 'beetle': 7,\n",
       " 'bicycle': 8,\n",
       " 'bottle': 9,\n",
       " 'bowl': 10,\n",
       " 'boy': 11,\n",
       " 'bridge': 12,\n",
       " 'bus': 13,\n",
       " 'butterfly': 14,\n",
       " 'camel': 15,\n",
       " 'can': 16,\n",
       " 'castle': 17,\n",
       " 'caterpillar': 18,\n",
       " 'cattle': 19,\n",
       " 'chair': 20,\n",
       " 'chimpanzee': 21,\n",
       " 'clock': 22,\n",
       " 'cloud': 23,\n",
       " 'cockroach': 24,\n",
       " 'couch': 25,\n",
       " 'crab': 26,\n",
       " 'crocodile': 27,\n",
       " 'cup': 28,\n",
       " 'dinosaur': 29,\n",
       " 'dolphin': 30,\n",
       " 'elephant': 31,\n",
       " 'flatfish': 32,\n",
       " 'forest': 33,\n",
       " 'fox': 34,\n",
       " 'girl': 35,\n",
       " 'hamster': 36,\n",
       " 'house': 37,\n",
       " 'kangaroo': 38,\n",
       " 'keyboard': 39,\n",
       " 'lamp': 40,\n",
       " 'lawn_mower': 41,\n",
       " 'leopard': 42,\n",
       " 'lion': 43,\n",
       " 'lizard': 44,\n",
       " 'lobster': 45,\n",
       " 'man': 46,\n",
       " 'maple_tree': 47,\n",
       " 'motorcycle': 48,\n",
       " 'mountain': 49,\n",
       " 'mouse': 50,\n",
       " 'mushroom': 51,\n",
       " 'oak_tree': 52,\n",
       " 'orange': 53,\n",
       " 'orchid': 54,\n",
       " 'otter': 55,\n",
       " 'palm_tree': 56,\n",
       " 'pear': 57,\n",
       " 'pickup_truck': 58,\n",
       " 'pine_tree': 59,\n",
       " 'plain': 60,\n",
       " 'plate': 61,\n",
       " 'poppy': 62,\n",
       " 'porcupine': 63,\n",
       " 'possum': 64,\n",
       " 'rabbit': 65,\n",
       " 'raccoon': 66,\n",
       " 'ray': 67,\n",
       " 'road': 68,\n",
       " 'rocket': 69,\n",
       " 'rose': 70,\n",
       " 'sea': 71,\n",
       " 'seal': 72,\n",
       " 'shark': 73,\n",
       " 'shrew': 74,\n",
       " 'skunk': 75,\n",
       " 'skyscraper': 76,\n",
       " 'snail': 77,\n",
       " 'snake': 78,\n",
       " 'spider': 79,\n",
       " 'squirrel': 80,\n",
       " 'streetcar': 81,\n",
       " 'sunflower': 82,\n",
       " 'sweet_pepper': 83,\n",
       " 'table': 84,\n",
       " 'tank': 85,\n",
       " 'telephone': 86,\n",
       " 'television': 87,\n",
       " 'tiger': 88,\n",
       " 'tractor': 89,\n",
       " 'train': 90,\n",
       " 'trout': 91,\n",
       " 'tulip': 92,\n",
       " 'turtle': 93,\n",
       " 'wardrobe': 94,\n",
       " 'whale': 95,\n",
       " 'willow_tree': 96,\n",
       " 'wolf': 97,\n",
       " 'woman': 98,\n",
       " 'worm': 99}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'aquarium_fish',\n",
       " 'baby',\n",
       " 'bear',\n",
       " 'beaver',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'beetle',\n",
       " 'bicycle',\n",
       " 'bottle',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'bridge',\n",
       " 'bus',\n",
       " 'butterfly',\n",
       " 'camel',\n",
       " 'can',\n",
       " 'castle',\n",
       " 'caterpillar',\n",
       " 'cattle',\n",
       " 'chair',\n",
       " 'chimpanzee',\n",
       " 'clock',\n",
       " 'cloud',\n",
       " 'cockroach',\n",
       " 'couch',\n",
       " 'crab',\n",
       " 'crocodile',\n",
       " 'cup',\n",
       " 'dinosaur',\n",
       " 'dolphin',\n",
       " 'elephant',\n",
       " 'flatfish',\n",
       " 'forest',\n",
       " 'fox',\n",
       " 'girl',\n",
       " 'hamster',\n",
       " 'house',\n",
       " 'kangaroo',\n",
       " 'keyboard',\n",
       " 'lamp',\n",
       " 'lawn_mower',\n",
       " 'leopard',\n",
       " 'lion',\n",
       " 'lizard',\n",
       " 'lobster',\n",
       " 'man',\n",
       " 'maple_tree',\n",
       " 'motorcycle',\n",
       " 'mountain',\n",
       " 'mouse',\n",
       " 'mushroom',\n",
       " 'oak_tree',\n",
       " 'orange',\n",
       " 'orchid',\n",
       " 'otter',\n",
       " 'palm_tree',\n",
       " 'pear',\n",
       " 'pickup_truck',\n",
       " 'pine_tree',\n",
       " 'plain',\n",
       " 'plate',\n",
       " 'poppy',\n",
       " 'porcupine',\n",
       " 'possum',\n",
       " 'rabbit',\n",
       " 'raccoon',\n",
       " 'ray',\n",
       " 'road',\n",
       " 'rocket',\n",
       " 'rose',\n",
       " 'sea',\n",
       " 'seal',\n",
       " 'shark',\n",
       " 'shrew',\n",
       " 'skunk',\n",
       " 'skyscraper',\n",
       " 'snail',\n",
       " 'snake',\n",
       " 'spider',\n",
       " 'squirrel',\n",
       " 'streetcar',\n",
       " 'sunflower',\n",
       " 'sweet_pepper',\n",
       " 'table',\n",
       " 'tank',\n",
       " 'telephone',\n",
       " 'television',\n",
       " 'tiger',\n",
       " 'tractor',\n",
       " 'train',\n",
       " 'trout',\n",
       " 'tulip',\n",
       " 'turtle',\n",
       " 'wardrobe',\n",
       " 'whale',\n",
       " 'willow_tree',\n",
       " 'wolf',\n",
       " 'woman',\n",
       " 'worm']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 32, 32]), torch.Size([32]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch , train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape,train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,input,hidden,output):\n",
    "        super().__init__()\n",
    "        self.cnn_block1= nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "        self.cnn_block2= nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "        self.cnn_block3= nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden*8*8,out_features=output)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.cnn_block1(x)\n",
    "        x= self.cnn_block2(x)\n",
    "        # x= self.cnn_block3(x)\n",
    "        # print(x.shape)\n",
    "        x=self.classifier(x)\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = CNN(input=3,hidden=10,output=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label = test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0147, -0.0284,  0.0306, -0.0294, -0.0798,  0.0092,  0.0072,  0.0697,\n",
       "          0.0395, -0.0047,  0.0226,  0.0172, -0.0033,  0.0577, -0.0144,  0.0567,\n",
       "         -0.0322,  0.0707, -0.0110,  0.0284,  0.0738, -0.0337,  0.0206,  0.0064,\n",
       "          0.1304,  0.0055,  0.0245,  0.0963,  0.0809,  0.0178,  0.0062,  0.0573,\n",
       "         -0.0095,  0.0048,  0.0209, -0.0435, -0.0176,  0.0126,  0.0264, -0.0054,\n",
       "         -0.0338, -0.0133,  0.0903,  0.0192, -0.0069, -0.0131,  0.0457, -0.0106,\n",
       "         -0.0558, -0.0274,  0.0232,  0.0107, -0.0381,  0.0078, -0.0719, -0.0085,\n",
       "         -0.0191,  0.0338,  0.0467,  0.1078, -0.0057,  0.0477,  0.0143,  0.0104,\n",
       "          0.0126, -0.0016,  0.0133, -0.0388, -0.0468,  0.0619,  0.0450, -0.0419,\n",
       "          0.0470,  0.0025, -0.0041, -0.0147,  0.0351, -0.0063, -0.0194,  0.0951,\n",
       "          0.0278, -0.0385,  0.0070, -0.0296,  0.0129,  0.0771,  0.0043,  0.0085,\n",
       "         -0.0739,  0.0207, -0.0484,  0.0012,  0.0389, -0.0511,  0.0053,  0.1055,\n",
       "         -0.0026,  0.0517,  0.0735, -0.0014]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model(image.to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=Model.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0-------\n",
      "Train loss: 4.36494 | Train acc: 4.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:12<00:38, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.32912 | Test acc: 56.25%\n",
      "\n",
      "epoch: 1-------\n",
      "Train loss: 3.71833 | Train acc: 14.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:25<00:25, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.42208 | Test acc: 37.50%\n",
      "\n",
      "epoch: 2-------\n",
      "Train loss: 3.36777 | Train acc: 20.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:38<00:12, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.01123 | Test acc: 31.25%\n",
      "\n",
      "epoch: 3-------\n",
      "Train loss: 3.17550 | Train acc: 24.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:51<00:00, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.58381 | Test acc: 68.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    print(f\"epoch: {epoch}-------\")\n",
    "\n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    \n",
    "\n",
    "    for batch,(X,Y) in enumerate(train_dataloader):\n",
    "        Model.train()\n",
    "\n",
    "        X,Y=X.to(device),Y.to(device)\n",
    "\n",
    "        y_pres = Model(X)\n",
    "\n",
    "        loss = loss_fn(y_pres,Y)\n",
    "\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=Y,\n",
    "                                 y_pred=y_pres.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_loss , test_acc = 0 , 0\n",
    "    Model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X_test ,Y_test in test_dataloader:\n",
    "\n",
    "            X_test,Y_test=X.to(device),Y.to(device)\n",
    "\n",
    "            \n",
    "\n",
    "            # forward pass\n",
    "            test_pred = Model(X_test)\n",
    "\n",
    "            # calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, Y_test)\n",
    "\n",
    "            # Accuracy\n",
    "            test_acc += accuracy_fn(Y_test,test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Calculate the test acc average per batch\n",
    "\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a CNN\n",
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Model architecture that replicates the TinyVGG\n",
    "    model from CNN explainer website.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input:int,\n",
    "                 hidden:int,\n",
    "                 output:int):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden,out_channels=hidden,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden*8*8, # there's a trick to calculating this\n",
    "                      out_features=output)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv_block1(x)\n",
    "        # print(x.shape)\n",
    "        x=self.conv_block2(x)\n",
    "        # print(x.shape)\n",
    "        x=self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input=3,hidden=10,output=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:torch.nn.Module,\n",
    "               data_loader:torch.utils.data.DataLoader,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device:torch.device = device):\n",
    "    \n",
    "    \"\"\"Performs a training with model trying to learn on data_loader.\"\"\"\n",
    "\n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch,(X,Y) in enumerate(data_loader):\n",
    "       \n",
    "\n",
    "        X,Y=X.to(device),Y.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Loss\n",
    "\n",
    "        loss = loss_fn(y_pred,Y)\n",
    "        train_loss +=loss # accumulate train loss\n",
    "        train_acc += accuracy_fn(y_true=Y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        # 5. optimizer step\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:torch.nn.Module,\n",
    "              data_loader:torch.utils.data.DataLoader,\n",
    "              loss_fn:torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device:torch.device=device):\n",
    "    \n",
    "\n",
    "    test_loss , test_acc = 0 , 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X ,Y in data_loader:\n",
    "            X,Y = X.to(device),Y.to(device)\n",
    "            # forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, Y)\n",
    "\n",
    "            # Accuracy\n",
    "            test_acc += accuracy_fn(Y,test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculate the test loss average per batch\n",
    "        test_loss /= len(data_loader)\n",
    "\n",
    "        # Calculate the test acc average per batch\n",
    "\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "from timeit import default_timer as timer\n",
    "train_strat = timer()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_step(model=model_2,\n",
    "              data_loader=train_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              optimizer=optimizer,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "\n",
    "    test_step(model=model_2,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "\n",
    "\n",
    "train_end = timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_gpu(model:torch.nn.Module,\n",
    "               data_loader:torch.utils.data.DataLoader,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\"\"\"\n",
    "    loss,acc = 0,0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X,Y in tqdm(data_loader):\n",
    "            # Make prediction\n",
    "            X,Y = X.to(device),Y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred,Y)\n",
    "\n",
    "            acc += accuracy_fn(Y,y_pred.argmax(dim=1))\n",
    "            \n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"Model_name\": model.__class__.__name__,\n",
    "            \"model_loss\":loss.item(),\n",
    "            \"model_acc\":acc}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 201.12it/s]\n"
     ]
    }
   ],
   "source": [
    "model_result = eval_model_gpu(model=Model,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_name': 'CNN',\n",
       " 'model_loss': 3.4409008026123047,\n",
       " 'model_acc': 21.206070287539937}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
